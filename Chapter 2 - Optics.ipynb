{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "# Chapter 2 - Optics\n",
    "\n",
    "In this article, we are goint to find out how an image is formed on an Image Plane. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "The overall principle is quite basic: An object reflects light that falls on an Image sensor, which captures the lights intensity and\n",
    "therefore forms an image. To ensure that every part of the scenery only falls onto the optical sensor at one spot only, we can introduce\n",
    "an optical barrier with a hole in it which ensures that - for each point in our scene - only light rays with a particular \n",
    "angle fall onto the image plane.\n",
    "We can therefore create an upside down copy of the scenery on our optical sensor. The smaller the barriers hole, the more angle-selective\n",
    "our camera becomes, the sharper the image appears. The hole is also known as aperture, or pinhole. \n",
    "\n",
    "![Pinhole Model, p. 7](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_2/1_pinhole_camera.png)\n",
    "*Figure 1: Concept of a Pinhole camera. [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/01_introduction.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "An ideal pinhole camera has - mathematically - an infinitely small pinhole to have an infinitely sharp image. In practice, this comes in\n",
    "hand with two problems: The smaller the pinhole, the less light we can capture on our sensor. Furhter, a pinhole smaller than 0.3mm will\n",
    "cause lightwave interferreneces, making the image blurry again due to diffraction effects. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "To combat these issues, lenses are used. They have the property that they bundle lightrays coming from the same point in our scenery\n",
    "into a (preferrably) single spot on the optical sensor. Lenses must fullfill two characteristics to be fitting camera lenses:\n",
    "- 1. Light rays that travel through the optical center of the lens will not be deviated\n",
    "- 2. Lightrays that fall parallel to the optical axis into the lens are focues in a so called \"focal point\" f behind the lens. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "With combining these two properties, we can derrie the \"thin lense equation\": From a single Object in our Scene at distanze Z and height A\n",
    "in front of our lens, we can construct two lighrays: One passing through the optical center, the other entering the lens parallel\n",
    "to the optical axis. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "To make the Object appear sharp, we have to ensure that both lighrays fall onto the same point on our optical sensor. Since the\n",
    "focal point is given by the lens properties, we can not vary the focal length *f* (distance between focal point and lens). What we \n",
    "can change is the position of the optical sensor: We can either bring it closer or farther to lens. We call the distance to the\n",
    "optical sensor *e*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "With looking back at similarity triangles principles, we can see that The objects elevation *A* in respect to the position of the \n",
    "sensor crossing point *B* must be the same as the distance to the Object *z* in respect to the distance from the Lens to the \n",
    "Image Sensor *e*. We therefore conduct that *B/A = e/z*. \n",
    "As a second equation, we can conduct that *B/A* must also be equal to the ration *e-f / f*. To simplify, we can also write\n",
    "*B/A = e/f - 1*.\n",
    "\n",
    "![Thin Lens equation, p. 17](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_2/2_thin_lens_equation.png)\n",
    "*Figure 2: Thin lens equation model visualization. [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/01_introduction.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "With combining these two equations, we get that *e/f - 1 = e/z* and finally **1/f = 1/z + 1/e**. Therefore, for a given\n",
    "distance *z*, the object only appears sharp if the optical sensor is distance *e* away from the Lens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "It becomes clear that if we move an Object further away (increasing *z*), the distance e must be changed to make the object appear\n",
    "sharp again. \n",
    "When the thin lens equation is not satisfied, the light rays do not intersect at the optical sensor, creating a blur circle which\n",
    "is perceived as \"unsharp\". Only a blur circle with radius less than 1 Pixel gives a sharp image. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "The distance between the focal Plane (where the light rays at this distance actually meet) and the image plane (optical sensor)\n",
    "is called $\\mathbf{\\delta}$, the diameter of a Pinhole is referred to as *L*. For simple pinhole cameras, this gives us a blur circle \n",
    "radius of $\\mathbf{\\dfrac{(\\dfrac{L}{2})}{R}=\\dfrac{e}{\\delta}} \\implies \\mathbf{R = \\dfrac{L \\cdot \\delta}{2 \\cdot e}}$. \n",
    "\n",
    "![Blur circle, p. 19](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_2/3_blur_circle.png)\n",
    "*Figure 3: Blur circle. [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/01_introduction.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Why is this relevant? Well, for large distances to our object *z* we can approximate our lens-based camera model with a pinhole camera,\n",
    "since the distance to any world object is much much larger than the focal length or the Lens size. Typically, smartphone cameras\n",
    "have focal lengths of 1.7mm and Lens sizes of < 1 cm. We can therefore focus at objects at infinity. This implies that the \n",
    "focal plane for objects that are inifinitely far away moves to the focal point. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "We can therefore safely aproximate that the focal length *f* is equal to the optical sensor distance *e* : *e ~= f*. This makes the \n",
    "relation between our objects elevation *A* and the point on the Image plane *B* even simpler: We don't have to consider two\n",
    "lightrays but just one falling straight throught the pinhole. This also leaves us with a simpler equation to\n",
    "find the point *B* where a object at distce *z* and elevation *A* would fall on the Image sensor: *B/A = f/z*, or *B = f/z x A*. \n",
    "Therefore, Objects twice as far away appear half as large in on the optical sensor. \n",
    "\n",
    "![Pinhole approximation, p. 22](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_2/4_pinhole_approximation.png)\n",
    "*Figure 4: Pinhole approximation. [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/01_introduction.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "The distance range in which an object appears sharp (R < 1 Pixel) is called the Depth of Field (DoF). The smaller the apperture, \n",
    "the larger the Depth of Field, but the less light we have left for the Image Sensor. \n",
    "Further, the lens size at a fixed focal length defines the biggest Angle the camera can perceive, the Field of View (FoV). \n",
    "We can also increase/decrease the FoV by changing the focal length: Larger focal lengths intuitively result in a more narrow\n",
    "viewing angle. The ratio between the focal length *f*, lenswidth *W* and the FoV angle *$\\theta$* can be simply expressed via a tangential relation:\n",
    "*tan($\\theta$/2) = W/2 x f*\n",
    "\n",
    "![FoV-Focal length ratio, p. 22](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_2/5_ration_fow_focal_length.png)\n",
    "*Figure 5: Ratio between Field of View and Focal length. [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/01_introduction.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "An interesting consequence of perspecitve projection is that parallel lines in the 3D world are no longer perceived as parallel on the 2D image\n",
    "plane. Neither are angles preserved. Further, it seems that parallel lines in an image will cross at some point, the so called\n",
    "vanishing point. With tracking all these vanishing points, we can fit a vanishing line through them: A line on which all vanishing\n",
    "points land. We observe two vanihshing lines: one for horizontal and one for vertical parallel lines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "![Vanishing Lines and Points](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_2/6_vanishing_points_and_lines.png)\n",
    "*Figure 6: Vanishing Lines and Points. [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/01_introduction.pdf)*\n",
    "\n",
    "\n",
    "\n",
    "**TODO: Copy Pasta page 57**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
