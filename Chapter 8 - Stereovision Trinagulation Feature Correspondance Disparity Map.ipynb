{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 - Stereovision, Trinagulation, Feature Correspondance, Disparity Map\n",
    "\n",
    "In this acticle we introduce the topic of stereo vision which is the application of mutiple camera views to get information about the depth of the view. Using stereo Visione one can derive the world locaton of a point from its images in different camera views. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple View Geometry\n",
    "\n",
    "There are different variations of multiple view geometry as this term encompasses all aplication working with multiple view of the save object from different angles. This can be from stereo cameras which have multiple carmeras in the same devices or different views from different devices. So let un defined two different terms which are important to keep in mind for the rest of the article.\n",
    "\n",
    "**3D reconstruction from multiple views**: For this application we assume that the camera intrinsics K are known. Also We assume that we knoe the Ratation and the Transaltion between different views. This can be by using some IMUs or other mechanisms. The Goal is to reconstruct the 3D structure of the objecft drim many different images.\n",
    "\n",
    "**Structure From Motion (SFM)**: In this application we do now know any intrinsics K or any Translation or Rotation. Therefore the goal is to recover the intrinsics as well as the camera pose together ith the 3D structure of the scene.\n",
    "\n",
    "In the case of exact 2 views we call the first case **Depth from stereo** and the second one **2-view Structure from Motion**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depth from Stereo\n",
    "\n",
    "For a single camera only back-project the ray on which the image point lies but we can not determine at which depth the actual object is located. An illustraiotn for that you can see in the left side in Figure 1. When using two cameras as we do in stereo cameras we have such a ray-back-projection originating from different locations in the world. As a result we can just see where the rays from the left camera intersect with the ones from the right camera to know at which depth the object lies.\n",
    "\n",
    "![Perspective and Stereo](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_8/1_projection_and_stereo.png)\n",
    "*Figure 1: Perspective and Stereo [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/07_multiple_view_geometry_1.pdf)*\n",
    "\n",
    "Our brain also work like this and thats the reasons why most amymals and humans have two eyes. This is so that they are able to estimate the depth of the secene they are seeing. Our brain mixes the two images that we are seeing, one from each eye, into one single image. This is similar to the processing our brain makes to turn the observed images as the eyes observe the world in an upside-dwn view.\n",
    "\n",
    "You can experience the effect of stereo vision simpli by holting up one finger infornt of your eyes and then closing the left eye only, and short after that the right weye only. You will observe that the fingers seems to jumping from left to right.\n",
    "This observed horizontal displacement is called **disparity**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disparity\n",
    "\n",
    "The displacement between two images allows us to percept depth. The displacement in the image is always along the same axis as the displacement of the perceptors. Usually tthe perceptors are displaced horizonally as for the example with the eyes of animals of also most standard stereo cameras. One application where this is used are the anaglyphs. These are the images with red and blue thint which appear with depth when you look trough soe glasses where infron of the eye there is a blue filter and infront of the othere there is a red filter.\n",
    "\n",
    "Another application is the stereogram where you can see certain images in depth when focusing behind the actual image. In the example below you have to focus about 10cm behind the image plane to then hopefully see the plant. For this effect the stereo vision is needed. You can try it out by clonsing one eye when you have been able to focus correctly to see tha plant. Once you close one eye you will instatly lose the vision of the plant.\n",
    "\n",
    "![Stereogram](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_8/2_stereogram.png)\n",
    "*Figure 2: Stereogram [source](http://Image from magiceye.com)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stereo Vision\n",
    "\n",
    "The basic principle of stereo vision is to recosntruct the 3D position of a point by intersecting its rays thouth its images in different views. For this we need the position of the camera so that we know the abslute worl position of the ray. also we need to knwo which points of the different view images to correspond (point correspondence)\n",
    "In general the different the cameras image planes can be orientated independently from each other. However the problem becomes easier when the imageplanes are aligned and also when the same camera intrinsics can be applied to all images. Meaning the cameras are identical.\n",
    "\n",
    "![Stereo simple and general case](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_8/3_stereo_cases.png)\n",
    "*Figure 3: Stereo simple and general case [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/07_multiple_view_geometry_1.pdf)*\n",
    "\n",
    "In figure 4 we want to find an expression forthe distance from the image to the object which is denoted as $Z_P$. We can see that both cameras $C_l$ and $C_r$ have the same focal length $f$. Also they are prefectly allinged with a horizontal displacement $b$, which we call **baseline**. From the similarity of the triangles in green and yellow we know that the relation betwen the length of the red lines must be the same as the relation of the lengths of the blue lines. Therefore we know:\n",
    "\n",
    "\\begin{align*}\n",
    "\\dfrac{f}{Z_P} &= \\dfrac{u_l}{X_p} \\\\\n",
    "\\dfrac{f}{Z_P} &= \\dfrac{-u_r}{b-X_p}\n",
    "\\end{align*}\n",
    "\n",
    "From this we can derive:\n",
    "\n",
    "\\begin{align*}\n",
    "Z_P = \\dfrac{bf}{u_l-u_r} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "$u_l-u_r$ is what we have previously introduced as **disparity**, the displacement of the same object on the different images in pixel coordinates.\n",
    "\n",
    "![Stereo Vision simple](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_8/4_stereo_vision_simple.png)\n",
    "*Figure 4: Stereo Vision simple [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/07_multiple_view_geometry_1.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For practical applications some questions may arise. For example what is optimal baseline distance? Because if the it is too large, then the minimum measurable depth increases and close object can not be searched for. If the baseline is too small then there is a large depth error.\n",
    "\n",
    "![Large and Small Baseline](https://github.com/joelbarmettlerUZH/PyVisualOdometry/raw/master/img/chapter_8/5_large_and_small_baseline.png)\n",
    "*Figure 5: Large and Small Baseline [source](http://rpg.ifi.uzh.ch/docs/teaching/2019/07_multiple_view_geometry_1.pdf)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Work description: Stereo vision: rectification, epipolar matching,\n",
    "disparity, triangulation\n",
    "\n",
    "TODO!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
