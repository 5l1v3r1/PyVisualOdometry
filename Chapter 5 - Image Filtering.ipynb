{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "markdown",
      "source": "# Chapter 5 - Image Filtering\n\nIn this chapter, we\u0027re introducing the concept of Image Filtering. \nFilters can be applied on 2D Image data either for various applications. We can broadly differenciate low-pass filters smooth images\n(retrain low-frequenciy components) and high-pass filters (retain contours / edges, e.g. high frequencies). \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Low-pass filters\nLow pass filters are typically applied to reduce noise in images. Noise can be deen as random artifacts in an image. \nFor example, salt \u0026 pepper noise describes the random occurence of black / white pixels in the image, while\ngaussian noise is a random increase/decrease in each pixels color value, following a gaussian distribution.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Low-pass filters assume that the pixel variation in the image should be lower than perceived, e.g. pixels should have a\ncolor value close to their neighbours. Low-pass filters therefore replace each pixels value with an average of the values in \nthe pixels neighbourhood. The neighbours can either be weighted based on their distance to the center pixel, or equally. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Moving a filter over all possible positions in an image is called a *convolution*, the filter is called a *Kernel* or *Mask* \nand denoted *H*. \nWhen convoluting a filter over an image, we flip the kernel by 180Â° before performing at each position before computing the weighted \naverage between the filter values and the pixel. If we do not flip the kernel, we speak of a cross-correlation instead of a convolution.\nFor symmetric filters like \"Gaussian Filter\" or \"Median Filter\", a convolution and a cross-correlation will of course produce\nthe same results. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "In the following example, a low-pass box-filter is applied over an image showing a white square on a black background.\n\n![Filter example, p. 15]()\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "The output is - of course - a blurred version of the very same image.\n\n![Filter output, p. 20]()\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "While the box filter smoothens an image quite well, it produces horizontal and vertical aftifacts since the filter itself has\nsharp edges. These artifacts are also called \"aliasing\" and is caused by the high frequency components of the box filter.\nA better way to smooth an image is with a gaussian filter, a filter implementing the 2D gaussian function. \nFor perfect results, take a large gaussian filters with smooth edges, e.g. low standard derivation that ensures that the outermost\nvalues of the filter are close to 1 while preserving a smooth derivative. \n\n![Gaussian Filter, p. 22]()\n![Gaussian Filter comparison, p. 26]()\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "When we apply any filter on an image, the question remains how to deal with the image boundary. Since - in most cases - we don\u0027t\nwant the resulting image to be smaller than the input image, we have to simulate additional boundary pixels. \nThere are different strategies with varying results, like zero-padding (surrounding black pixels), wrap-around (repeating the image),\ncopy-edge (always use outermost pixel values) or reflect accross edge (mirroring around edge, gives best results). \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Non-linear Low-pass filters\n\nGaussian filters or box-filters do not denoise salt \u0026 pepper noise since they get influenced by outliers by a high degree. \nThat\u0027s where **median filters** come into play. They can not be interpreted as a classical convolution filter like a Gaussian\nfilter, it rather takes the median pixel value from the neighbourhood. The median filter is therefore much less influenced\nby strong noise, while he also preserves edges much better than the linear smoothing filters. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Another such filter is the **billateral filter**. It acts like a median filter with preserving edges even more by adapting the kernel\nlocally to the intensitiy profile of the underlaying image. They only average pixels with similar brightness: Pixels that fall below\na brightness difference compared to the center pixel. \n\n![Billateral filter, p. 37]()\n\nThe extend to which neighbouring pixels have to be similar to the central pixel is controlled via a factor *sigma*.\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## High-pass filters\n\nHigh-pass filters are mainly used for edge detection since react to sharp change in pixel intensity. Edges are sharp changes in\nan image functions intensity value. Applying the first derivative on an image would leave us with an image where sharp edges \nare shown. We therefore construct a filter that acts like a derivative by approximating the image derivative \n*dI(x,y) / dx ~ I(x+1, y) - I(x,y)* and *dI(x,y) / dy ~ I(x, y+1) - I(x,y)*. \nSo we essentially compare each pixel to its direct neighbour and take the difference as an output. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "More advanced filters are larger in size and therefore produce less artifacts. The sobel-filter is an example for a larger\nderivative filter:\n\n![Sobel filter, p. 48]()\n\nThe direction of the edge can be determined by calculating the pixel regions gradient, so the diretion of fastest intensity change.\nThe gradient direction is given by *angle \u003d arctan2(dI/dx, dI/dy)*, so the two dimensional arcus tangens of the image derivative\nvalues. The edge strenght is given by the gradients magnitude: *strength \u003d sqrt((dI/dx)^2 + (dI/dy)^2).\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "A big problem for high-pass filters is gaussian noise: there will always be a steep difference between two neighbouring pixels, caused\nby normal gaussian noise produced by the image sensor. It is therefore best practice to softly filter the image first with a \ngaussian filter before applying a high-pass filter. \n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "In the following graphic, we see the original image I, the kernel H, the resulting image when H is applied I*H as well as the derrived\nimage d(I*H)/dx\n\n![Processes, p. 51]()\n\nA way better approach is to directly include the smoothing in the filter itself, giving us the filter dH/dx as seen in\nthe following image:\n\n![Smoothing high-pass filter, p. 52]()\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "This is called a \"derivative of gaussian\" filter: it multiplies a normal gaussian filters with a high-pass 2x1 derivative filter. \n\n![Derivative of gaussian, p. 53]()\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Since we deal with two partial derivatives, we\u0027d need to filter the image twice. A solution to this is given by the \n\"Laplacian of Gaussian\"-Filter, which finds the derivative in all directions simultaniously. It is constructed by\nsubtracting a smaller radius gaussian Filter from a large radius gaussian filter.\n\n![Difference of gaussians, p. 56]()\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Canny edge detection\n\nCanny edge detection uses partial gaussian derivative filters to find all corners in an image. It then sets all pixelsvalues to 0 that\nfall under a given threshold. Finally, Canny takes the local maximum of any corner along the gradient direction, e.g. it only\ntakes the peak of a wide edge. \n\n![Canny edge detection, p. 62]()\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}